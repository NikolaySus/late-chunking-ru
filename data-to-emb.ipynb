{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1173893c4f0ea56",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Создание эмбеддингов традиционным и новым методами\n",
    "В этом ноутбуке датасет https://huggingface.co/datasets/ai-forever/ria-news-retrieval преобразован в эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cd1695-b616-4e94-9fa1-e8f080418dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunked_pooling import chunked_pooling, chunk_by_sentences\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4dd33e-fa2c-49d7-9831-dd1ae37e6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.abspath('')\n",
    "queries = pd.read_json(basePath + \"\\\\ai-forever-ria-news-retrieval\\\\queries.jsonl\", lines=True)\n",
    "corpus = pd.read_json(basePath + \"\\\\ai-forever-ria-news-retrieval\\\\corpus.jsonl\", lines=True)\n",
    "test = pd.read_json(basePath + \"\\\\ai-forever-ria-news-retrieval\\\\test.jsonl\", lines=True)\n",
    "del corpus['title']\n",
    "del test['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efaded-9f3c-410b-b823-630f0c20cc7a",
   "metadata": {},
   "source": [
    "### Единственное проблемное место датасета, но это было исправлено в будущем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c69626-9f6a-459f-b652-f3ae928ec79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>3840</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id text\n",
       "3840  3840     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[corpus['text'] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6351242-3002-4771-943d-ad1e5643c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_ch_emb(calc_chunk):\n",
    "    device = torch.device(\"cuda\")\n",
    "    # load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v3', trust_remote_code=True, device_map = 'cuda')\n",
    "    model = AutoModel.from_pretrained('jinaai/jina-embeddings-v3', trust_remote_code=True, device_map = 'cuda')\n",
    "    result = pd.DataFrame({\n",
    "        \"chunk\" : [],\n",
    "        \"trad_chunk_embedding\" : [],\n",
    "        \"new_chunk_embedding\" : [],\n",
    "        \"doc_id\" : [],\n",
    "    })\n",
    "    result.astype('object')\n",
    "    last_idx = 0\n",
    "    for doc_id, doc in calc_chunk.iterrows():\n",
    "        doc_chunks, doc_span_annotations = chunk_by_sentences(doc['text'], tokenizer)\n",
    "        doc_trad_chunk_embeddings = model.encode(doc_chunks)\n",
    "        doc_inputs = tokenizer(doc['text'], return_tensors='pt')\n",
    "        doc_model_output = model(**(doc_inputs.to(device)))\n",
    "        doc_new_chunk_embeddings = chunked_pooling(doc_model_output, [doc_span_annotations])[0]\n",
    "        for i, (chunk, trad_chunk_embedding, new_chunk_embedding) in enumerate(zip(doc_chunks, doc_trad_chunk_embeddings, doc_new_chunk_embeddings)):\n",
    "            result.loc[last_idx + i] = np.array([chunk, trad_chunk_embedding, new_chunk_embedding, doc['_id']], dtype=object)\n",
    "        last_idx += len(doc_chunks)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f3a45-78ea-4402-af7f-90b7e61b9a23",
   "metadata": {},
   "source": [
    "### Для ускорения рассчётов данные были разбиты на 22 куска для парааллельной обработки на разных машинах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b157e143-4bb0-4892-9774-077a2da494d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorku\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "chunked_corpus  = np.array_split(corpus, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aec35e8-c623-4562-b27d-4faedc2d7482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 54min 26s\n",
      "Wall time: 4h 53min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(252887, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chunks12 = do_ch_emb(chunked_corpus[12])\n",
    "chunks12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e4cbc9-9eec-4570-a2ae-bc0b491b1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks12.to_pickle(basePath + \"\\\\ai-forever-ria-news-retrieval\\\\chunks_embedded_12.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001fcf4-063e-4130-a2d3-3e755941844e",
   "metadata": {},
   "source": [
    "### Эмбеддинг запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a7be7-2e03-47fb-be0a-0ad5d39cba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v3', trust_remote_code=True, device_map = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40956bd-f81d-4a54-ad21-25383b498e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "queries['embedding'] = queries.apply(lambda q: model.encode(q['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe2fa8-321c-4884-b0f5-9b1b42f56ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98d0a-e423-4dd1-ae5f-47bba7f0ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.to_pickle(basePath + \"\\\\ai-forever-ria-news-retrieval\\\\queries_embedded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c7c22-4a7e-4d95-ab13-fc335ae9b39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
